import os
import sys
import json
import glob
import logging
import argparse
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from src.client import OllamaClient
from src.loader import MMLUDataLoader
from src.scorer import Scorer

# è¨­å®š Log
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("Main")

def main():
    parser = argparse.ArgumentParser(description="Automated Prompt Evaluation System")
    parser.add_argument("--model", type=str, default="llama3", help="Ollama model name")
    parser.add_argument("--subsets", type=str, default="global_facts", help="Comma separated MMLU subsets")
    parser.add_argument("--split", type=str, default="validation", help="Dataset split")
    parser.add_argument("--prompt_dir", type=str, default="./prompts", help="Directory containing prompt JSONs")
    parser.add_argument("--output_dir", type=str, default="./results", help="Directory to save results")
    parser.add_argument("--limit", type=int, default=5, help="Num samples per subset (use 0 for all)")
    
    args = parser.parse_args()
    
    # 1. æº–å‚™å…ƒä»¶
    client = OllamaClient(model_name=args.model)
    subsets_list = [s.strip() for s in args.subsets.split(',')]
    
    # [ä¿®æ­£ 1] å°‡ limit å‚³å…¥ Loaderï¼Œè®“ Loader è² è²¬æ¯å€‹å­é›†å–å‰ N ç­†
    # æ³¨æ„ï¼šè«‹ç¢ºä¿ src/loader.py çš„ __init__ å·²ç¶“æ›´æ–°æ¥æ”¶ limit åƒæ•¸
    loader = MMLUDataLoader(subsets=subsets_list, split=args.split, limit=args.limit)
    
    scorer = Scorer(client, config_mode='Q_begin')

    # 2. è¼‰å…¥è³‡æ–™
    logger.info("Loading Dataset...")
    dataset = loader.load_data()
    
    # 3. ç¢ºä¿ç›®éŒ„å­˜åœ¨
    os.makedirs(args.output_dir, exist_ok=True)
    
    # 4. æƒææª”æ¡ˆä¸¦åŸ·è¡Œ
    json_files = glob.glob(os.path.join(args.prompt_dir, "*.json"))
    
    # [ä¿®æ­£ 2] è¨­å®š Scorer çš„ limit é‚è¼¯
    # å› ç‚º Loader å·²ç¶“è² è²¬ç¯©é¸è³‡æ–™äº†ï¼Œæ‰€ä»¥é€™è£¡å‚³çµ¦ Scorer 0 (ä»£è¡¨ä¸æŠ½æ¨£ï¼Œå…¨è·‘)
    if args.limit > 0:
        logger.info(f"ğŸ”§ Config: Loader took first {args.limit} items per subset. Total loaded samples: {len(dataset)}")
        scorer_limit = 0 
    else:
        logger.info("ğŸ”§ Config: Limit set to 0. Running on FULL dataset.")
        scorer_limit = 0

    for json_file in json_files:
        full_file_name = os.path.basename(json_file)
        base_name = os.path.splitext(full_file_name)[0]
        
        logger.info(f"Processing: {full_file_name}")
        
        with open(json_file, 'r') as f:
            data = json.load(f)
        
        results = []
        prompts = data.get("prompts", [])
        
        # [ä¿®æ­£ 3] ç¢ºä¿é€™è£¡çš„ç¸®æ’æ­£ç¢ºï¼Œä½æ–¼ for json_file è¿´åœˆå…§éƒ¨
        for idx, item in enumerate(prompts):
            # å…¼å®¹è™•ç†ï¼šç„¡è«–è¼¸å…¥æ˜¯å­—ä¸²é‚„æ˜¯ç‰©ä»¶ï¼Œéƒ½å–å‡º Prompt æ–‡å­—
            p_text = item if isinstance(item, str) else item.get("text", "")
            
            # é›–ç„¶è¼¸å‡ºä¸å­˜ IDï¼Œä½† Log é‚„æ˜¯å°ä¸€ä¸‹æ–¹ä¾¿ä½ çœ‹é€²åº¦
            p_id_log = f"p_{idx}" if isinstance(item, str) else item.get("id", f"p_{idx}")
            
            if not p_text: continue
            
            logger.info(f"Testing: {p_id_log}")
            
            # [ä¿®æ­£ 4] å‚³å…¥ scorer_limit (ç‚º 0ï¼Œä»£è¡¨åŸ·è¡Œæ‰€æœ‰ dataset å…§å®¹)
            res = scorer.score_instruction(p_text, dataset, num_samples=scorer_limit)
            
            results.append({
                "score": res['score'],
                "prompt": p_text,
                "count": res['num_evals']
            })
            
            logger.info(f"Score: {res['score']:.2%}")

        # è¼¸å‡ºçµæœæª”æ¡ˆ
        out_filename = f"{base_name}_result.json"
        out_path = os.path.join(args.output_dir, out_filename)
        
        with open(out_path, 'w', encoding='utf-8') as f:
            json.dump({
                "source_file": full_file_name,
                "model": args.model,
                "subsets": subsets_list,
                "results": results
            }, f, indent=2, ensure_ascii=False)
            
        logger.info(f"Saved results to: {out_filename}")

if __name__ == "__main__":
    main()